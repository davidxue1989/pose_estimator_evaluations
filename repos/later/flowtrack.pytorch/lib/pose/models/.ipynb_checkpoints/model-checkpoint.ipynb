{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = torch.Tensor(2,3,256,256)\n",
    "inp = Variable(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = nn.Sequential(nn.Conv2d(3,16,kernel_size=1,bias=True), nn.BatchNorm2d(16), nn.ReLU(inplace=True))\n",
    "l1_list = [nn.Conv2d(3,16,kernel_size=1,bias=True), nn.BatchNorm2d(16), nn.ReLU(inplace=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential (\n",
      "  (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (2): ReLU (inplace)\n",
      ")\n",
      "[Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1)), BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True), ReLU (inplace)]\n"
     ]
    }
   ],
   "source": [
    "print l1\n",
    "print l1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2 = nn.Sequential(nn.BatchNorm2d(3),nn.ReLU(inplace=True))\n",
    "l2_list = [nn.BatchNorm2d(3),nn.ReLU(inplace=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential (\n",
      "  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (1): ReLU (inplace)\n",
      ")\n",
      "[BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True), ReLU (inplace)]\n"
     ]
    }
   ],
   "source": [
    "print l2\n",
    "print l2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "( 0 , 0 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "    ... \n",
      "\n",
      "( 0 ,13 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "( 0 ,14 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "( 0 ,15 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "    ... \n",
      "\n",
      "( 1 ,13 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "( 1 ,14 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "( 1 ,15 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "[torch.FloatTensor of size 2x16x256x256]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = l2(inp)\n",
    "out = l1(out)\n",
    "print out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList (\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modules = nn.ModuleList()\n",
    "print modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList (\n",
      "  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (1): ReLU (inplace)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modules.extend(l2_list)\n",
    "print modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList (\n",
      "  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (1): ReLU (inplace)\n",
      "  (2): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (4): ReLU (inplace)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modules.extend(l1_list)\n",
    "print modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential (\n",
       "  (0): ModuleList (\n",
       "    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (1): ReLU (inplace)\n",
       "    (2): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (4): ReLU (inplace)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Sequential(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias=False\n",
    "class bottleneck(nn.Module):\n",
    "    def __init__(self, inplanes, outplanes, stride=1, shortcut=None, preact=True):\n",
    "        super(bottleneck, self).__init__()\n",
    "        planes = outplanes / 2\n",
    "        branch = []\n",
    "        if preact:\n",
    "            branch.extend([nn.BatchNorm2d(inplanes), nn.ReLU(inplace=True)])\n",
    "        branch.extend([\n",
    "                nn.Conv2d(inplanes, planes, kernel_size=1, bias=bias),\n",
    "                nn.BatchNorm2d(planes),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=bias),\n",
    "                nn.BatchNorm2d(planes),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(planes, outplanes, kernel_size=1, bias=bias) ])\n",
    "        self.branch = nn.Sequential(*branch)\n",
    "        self.shortcut = shortcut\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.branch(x)\n",
    "        residual = x\n",
    "        if self.shortcut is not None:\n",
    "            residual = self.shortcut(x)\n",
    "        out += residual\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottleneck (\n",
      "  (branch): Sequential (\n",
      "    (0): Conv2d(20, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): Conv2d(10, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "b1 = bottleneck(20,20,preact=False)\n",
    "print b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList (\n",
       "  (0): ModuleList (\n",
       "    (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU (inplace)\n",
       "  )\n",
       "  (1): ModuleList (\n",
       "    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (1): ReLU (inplace)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.ModuleList([nn.ModuleList(l1_list),nn.ModuleList(l2_list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**结论： `nn.ModuleList`的参数不能为嵌套数组（e.g.`[[],[]]`）**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试 MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss(size_average=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hm_j = torch.rand(16,24,32)\n",
    "out_j = torch.rand(16,24,32)\n",
    "hm_l = torch.rand(15,24,32)\n",
    "out_l = torch.rand(15,24,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hm_joint = Variable(hm_j).cuda()\n",
    "out_joint = Variable(out_j).cuda()\n",
    "hm_limb = Variable(hm_l).cuda()\n",
    "out_limb = Variable(out_l).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.3360\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss1 = criterion(hm_joint, out_joint) + criterion(hm_limb, out_limb)\n",
    "print loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hm = torch.cat((hm_j, hm_l))\n",
    "out = torch.cat((out_j, out_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heatmap = Variable(hm).cuda()\n",
    "output = Variable(out).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.1680\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss2 = criterion(heatmap, output)\n",
    "print loss2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `torch.nn.Module` 和 `torch.nn.functional` 的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = torch.randn(16, 240, 320)\n",
    "img_tcuda = img_tensor.cuda()\n",
    "img_var = Variable(img_tensor).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "( 0 ,.,.) = \n",
      " -2.8289e-01  1.0448e-01  1.0950e+00  ...   3.6303e-01  3.6255e-01 -4.1751e-01\n",
      "  7.5964e-01 -1.0138e+00 -1.8485e-01  ...   4.7005e-01  4.3675e-01  1.6384e-01\n",
      "  5.8329e-01 -6.8565e-01  1.8973e-01  ...   9.2514e-01 -1.0894e+00  3.0276e-02\n",
      "                 ...                   ⋱                   ...                \n",
      "  7.5917e-01 -6.7922e-01 -1.7166e-02  ...   8.2920e-01  4.7255e-01 -5.4289e-01\n",
      " -9.7498e-01 -7.7489e-01 -1.5343e+00  ...   4.2520e-01  9.8323e-01  1.9160e+00\n",
      " -1.1915e-01 -1.7943e-01  6.4091e-01  ...  -9.4911e-02  4.4253e-01  3.4878e-01\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.0208e+00 -5.1129e-01 -1.1611e+00  ...  -1.2994e+00  1.4877e+00  7.1894e-01\n",
      "  1.4505e-01 -8.2797e-01  9.5891e-01  ...   3.2716e-01  1.0978e+00  1.3808e+00\n",
      "  2.5027e+00 -1.2795e+00  5.3267e-01  ...   1.1299e+00 -5.1431e-01  3.4596e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.6621e-01 -1.1852e+00 -3.7108e-01  ...  -3.1146e-01 -6.3700e-01 -1.5510e+00\n",
      "  6.6750e-02  2.9912e-01 -1.8818e+00  ...  -1.6428e-01  1.6483e+00  2.4159e-02\n",
      " -1.2403e+00 -3.6827e-01 -9.2823e-01  ...   1.9713e+00 -1.8615e+00 -9.8531e-01\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -1.7211e+00 -5.1021e-01  2.9825e-01  ...   9.4409e-01  1.2405e+00  1.4787e+00\n",
      " -7.9071e-01 -1.1172e+00  9.9461e-01  ...  -1.2024e-01 -8.1861e-01 -1.4066e-01\n",
      "  1.9189e+00 -1.8158e-01 -1.4400e+00  ...  -7.7487e-01  1.5492e+00 -1.3302e+00\n",
      "                 ...                   ⋱                   ...                \n",
      " -4.7472e-01  1.8367e-01  1.4469e-01  ...  -1.7264e+00 -4.5495e-01 -1.7674e+00\n",
      "  1.7818e+00 -8.5063e-01  9.3280e-01  ...  -3.0742e-01 -1.9127e-02  5.6432e-01\n",
      "  1.5733e+00  8.2863e-01 -5.1212e-03  ...  -7.0258e-01 -1.3754e+00  1.2620e+00\n",
      "... \n",
      "\n",
      "(13 ,.,.) = \n",
      " -4.7402e-01  2.2417e+00  1.1863e-01  ...  -1.4892e+00  1.7069e+00 -1.6572e+00\n",
      "  2.6694e-01  1.2107e+00 -6.3448e-02  ...  -1.3918e+00  3.2108e-01  1.8299e+00\n",
      " -1.9546e+00 -7.9685e-01 -1.1774e+00  ...  -3.2080e-01  7.4067e-01  1.8705e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -3.9507e-02  2.1246e-01  1.6065e+00  ...  -6.0182e-02  1.2831e+00 -7.1823e-01\n",
      "  7.9232e-01  5.0208e-01  1.9596e-01  ...   2.4929e-01  2.5050e-01 -1.3231e+00\n",
      "  1.3120e-01 -2.6528e-01  3.6703e-01  ...   3.3238e-01 -4.8698e-01 -6.3091e-01\n",
      "\n",
      "(14 ,.,.) = \n",
      "  1.5836e+00  2.2535e+00  1.1993e-01  ...  -7.8555e-01 -7.6250e-01  5.6515e-01\n",
      "  2.3536e+00  1.3208e-01  2.6503e-01  ...   2.2923e+00 -1.5060e+00  3.0145e-01\n",
      " -1.5117e-01  1.9603e+00 -1.2009e+00  ...   4.2638e-01  1.3965e+00 -6.9498e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -6.0525e-02 -1.7986e-01 -8.7696e-01  ...  -1.8995e+00 -6.6316e-01  1.0824e-01\n",
      "  3.5083e-01  1.7822e+00  9.6819e-01  ...  -1.0807e-01  2.1175e+00 -5.7597e-01\n",
      " -2.8011e-01  1.0732e+00 -1.8818e-01  ...  -3.2343e-01  7.1358e-02 -2.6135e+00\n",
      "\n",
      "(15 ,.,.) = \n",
      " -3.7925e-01  2.2380e-01 -3.3062e-01  ...  -7.2801e-01 -9.9739e-01  3.6055e-02\n",
      "  5.3173e-01  2.5270e-02 -8.0151e-01  ...   3.2378e-01 -6.7567e-01  2.4261e-01\n",
      "  2.0490e-01 -2.8185e-01  5.5683e-01  ...   1.6639e+00  9.4715e-02  5.3088e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -2.2097e+00  7.6006e-01 -3.4906e-02  ...   3.5511e-01 -5.3538e-01  6.1429e-01\n",
      "  9.4341e-01  6.8466e-01 -2.2062e-01  ...   1.3358e+00 -9.6689e-02  1.0011e+00\n",
      "  8.2614e-01 -8.0914e-01 -9.2785e-01  ...  -6.6531e-02 -3.8863e-01 -1.4727e+00\n",
      "[torch.cuda.FloatTensor of size 16x240x320 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -2.8289e-01  1.0448e-01  1.0950e+00  ...   3.6303e-01  3.6255e-01 -4.1751e-01\n",
      "  7.5964e-01 -1.0138e+00 -1.8485e-01  ...   4.7005e-01  4.3675e-01  1.6384e-01\n",
      "  5.8329e-01 -6.8565e-01  1.8973e-01  ...   9.2514e-01 -1.0894e+00  3.0276e-02\n",
      "                 ...                   ⋱                   ...                \n",
      "  7.5917e-01 -6.7922e-01 -1.7166e-02  ...   8.2920e-01  4.7255e-01 -5.4289e-01\n",
      " -9.7498e-01 -7.7489e-01 -1.5343e+00  ...   4.2520e-01  9.8323e-01  1.9160e+00\n",
      " -1.1915e-01 -1.7943e-01  6.4091e-01  ...  -9.4911e-02  4.4253e-01  3.4878e-01\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.0208e+00 -5.1129e-01 -1.1611e+00  ...  -1.2994e+00  1.4877e+00  7.1894e-01\n",
      "  1.4505e-01 -8.2797e-01  9.5891e-01  ...   3.2716e-01  1.0978e+00  1.3808e+00\n",
      "  2.5027e+00 -1.2795e+00  5.3267e-01  ...   1.1299e+00 -5.1431e-01  3.4596e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.6621e-01 -1.1852e+00 -3.7108e-01  ...  -3.1146e-01 -6.3700e-01 -1.5510e+00\n",
      "  6.6750e-02  2.9912e-01 -1.8818e+00  ...  -1.6428e-01  1.6483e+00  2.4159e-02\n",
      " -1.2403e+00 -3.6827e-01 -9.2823e-01  ...   1.9713e+00 -1.8615e+00 -9.8531e-01\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -1.7211e+00 -5.1021e-01  2.9825e-01  ...   9.4409e-01  1.2405e+00  1.4787e+00\n",
      " -7.9071e-01 -1.1172e+00  9.9461e-01  ...  -1.2024e-01 -8.1861e-01 -1.4066e-01\n",
      "  1.9189e+00 -1.8158e-01 -1.4400e+00  ...  -7.7487e-01  1.5492e+00 -1.3302e+00\n",
      "                 ...                   ⋱                   ...                \n",
      " -4.7472e-01  1.8367e-01  1.4469e-01  ...  -1.7264e+00 -4.5495e-01 -1.7674e+00\n",
      "  1.7818e+00 -8.5063e-01  9.3280e-01  ...  -3.0742e-01 -1.9127e-02  5.6432e-01\n",
      "  1.5733e+00  8.2863e-01 -5.1212e-03  ...  -7.0258e-01 -1.3754e+00  1.2620e+00\n",
      "... \n",
      "\n",
      "(13 ,.,.) = \n",
      " -4.7402e-01  2.2417e+00  1.1863e-01  ...  -1.4892e+00  1.7069e+00 -1.6572e+00\n",
      "  2.6694e-01  1.2107e+00 -6.3448e-02  ...  -1.3918e+00  3.2108e-01  1.8299e+00\n",
      " -1.9546e+00 -7.9685e-01 -1.1774e+00  ...  -3.2080e-01  7.4067e-01  1.8705e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -3.9507e-02  2.1246e-01  1.6065e+00  ...  -6.0182e-02  1.2831e+00 -7.1823e-01\n",
      "  7.9232e-01  5.0208e-01  1.9596e-01  ...   2.4929e-01  2.5050e-01 -1.3231e+00\n",
      "  1.3120e-01 -2.6528e-01  3.6703e-01  ...   3.3238e-01 -4.8698e-01 -6.3091e-01\n",
      "\n",
      "(14 ,.,.) = \n",
      "  1.5836e+00  2.2535e+00  1.1993e-01  ...  -7.8555e-01 -7.6250e-01  5.6515e-01\n",
      "  2.3536e+00  1.3208e-01  2.6503e-01  ...   2.2923e+00 -1.5060e+00  3.0145e-01\n",
      " -1.5117e-01  1.9603e+00 -1.2009e+00  ...   4.2638e-01  1.3965e+00 -6.9498e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -6.0525e-02 -1.7986e-01 -8.7696e-01  ...  -1.8995e+00 -6.6316e-01  1.0824e-01\n",
      "  3.5083e-01  1.7822e+00  9.6819e-01  ...  -1.0807e-01  2.1175e+00 -5.7597e-01\n",
      " -2.8011e-01  1.0732e+00 -1.8818e-01  ...  -3.2343e-01  7.1358e-02 -2.6135e+00\n",
      "\n",
      "(15 ,.,.) = \n",
      " -3.7925e-01  2.2380e-01 -3.3062e-01  ...  -7.2801e-01 -9.9739e-01  3.6055e-02\n",
      "  5.3173e-01  2.5270e-02 -8.0151e-01  ...   3.2378e-01 -6.7567e-01  2.4261e-01\n",
      "  2.0490e-01 -2.8185e-01  5.5683e-01  ...   1.6639e+00  9.4715e-02  5.3088e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -2.2097e+00  7.6006e-01 -3.4906e-02  ...   3.5511e-01 -5.3538e-01  6.1429e-01\n",
      "  9.4341e-01  6.8466e-01 -2.2062e-01  ...   1.3358e+00 -9.6689e-02  1.0011e+00\n",
      "  8.2614e-01 -8.0914e-01 -9.2785e-01  ...  -6.6531e-02 -3.8863e-01 -1.4727e+00\n",
      "[torch.cuda.FloatTensor of size 16x240x320 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print img_tcuda\n",
    "print img_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool_module = nn.MaxPool2d(kernel_size = 3, stride = 1, padding = 1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  7.5964e-01  1.0950e+00  1.0950e+00  ...   1.5959e+00  4.7005e-01  4.3675e-01\n",
      "  7.5964e-01  1.0950e+00  1.0950e+00  ...   1.5959e+00  9.2514e-01  4.3675e-01\n",
      "  7.5964e-01  1.5366e+00  1.5366e+00  ...   1.5959e+00  9.2514e-01  4.3675e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.3831e+00  1.3831e+00  6.1270e-01  ...   2.6950e+00  1.9160e+00  1.9160e+00\n",
      "  7.5917e-01  7.5917e-01  6.4091e-01  ...   9.8323e-01  1.9160e+00  1.9160e+00\n",
      " -1.1915e-01  6.4091e-01  6.4091e-01  ...   9.8323e-01  1.9160e+00  1.9160e+00\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.0208e+00  1.0208e+00  1.2072e+00  ...   2.2230e+00  1.4877e+00  1.4877e+00\n",
      "  2.5027e+00  2.5027e+00  1.2072e+00  ...   2.2230e+00  1.4877e+00  1.4877e+00\n",
      "  2.5027e+00  2.5027e+00  1.2072e+00  ...   2.2230e+00  1.3808e+00  1.3808e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.6621e-01  6.6621e-01  4.0690e-01  ...   1.6483e+00  1.6483e+00  1.6483e+00\n",
      "  6.6621e-01  6.6621e-01  3.6104e-01  ...   1.9713e+00  1.9713e+00  1.6483e+00\n",
      "  2.9912e-01  2.9912e-01  2.9912e-01  ...   1.9713e+00  1.9713e+00  1.6483e+00\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -5.1021e-01  9.9461e-01  9.9461e-01  ...   1.2405e+00  1.4787e+00  1.4787e+00\n",
      "  1.9189e+00  1.9189e+00  1.6152e+00  ...   1.5492e+00  1.5492e+00  1.5492e+00\n",
      "  1.9189e+00  1.9189e+00  1.6152e+00  ...   1.5492e+00  1.5492e+00  1.5492e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  2.1397e+00  2.1397e+00  2.1397e+00  ...   9.7082e-01  1.6140e+00  1.6140e+00\n",
      "  1.7818e+00  1.7818e+00  1.6480e+00  ...   9.7082e-01  1.2620e+00  1.2620e+00\n",
      "  1.7818e+00  1.7818e+00  1.6480e+00  ...   9.7082e-01  1.2620e+00  1.2620e+00\n",
      "... \n",
      "\n",
      "(13 ,.,.) = \n",
      "  2.2417e+00  2.2417e+00  2.2417e+00  ...   1.7069e+00  1.8299e+00  1.8299e+00\n",
      "  2.2417e+00  2.2417e+00  2.2417e+00  ...   1.7069e+00  1.8299e+00  1.8299e+00\n",
      "  1.2107e+00  2.8876e+00  2.8876e+00  ...   1.4901e+00  1.8299e+00  1.8299e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  7.9232e-01  1.6065e+00  1.6065e+00  ...   1.2831e+00  1.2831e+00  1.2831e+00\n",
      "  7.9232e-01  1.6065e+00  1.7276e+00  ...   1.2831e+00  1.2831e+00  1.2831e+00\n",
      "  7.9232e-01  7.9232e-01  1.7276e+00  ...   3.3238e-01  3.3238e-01  2.5050e-01\n",
      "\n",
      "(14 ,.,.) = \n",
      "  2.3536e+00  2.3536e+00  2.2535e+00  ...   2.2923e+00  2.2923e+00  5.6515e-01\n",
      "  2.3536e+00  2.3536e+00  2.2535e+00  ...   2.2923e+00  2.2923e+00  1.3965e+00\n",
      "  2.3536e+00  2.3536e+00  1.9603e+00  ...   2.2923e+00  2.2923e+00  1.3965e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.7822e+00  1.7822e+00  1.7822e+00  ...   2.1175e+00  2.1175e+00  2.1175e+00\n",
      "  1.7822e+00  1.7822e+00  1.7822e+00  ...   2.1175e+00  2.1175e+00  2.1175e+00\n",
      "  1.7822e+00  1.7822e+00  1.7822e+00  ...   2.1175e+00  2.1175e+00  2.1175e+00\n",
      "\n",
      "(15 ,.,.) = \n",
      "  5.3173e-01  5.3173e-01  1.6900e+00  ...   3.2378e-01  3.2378e-01  2.4261e-01\n",
      "  5.3173e-01  5.5683e-01  1.6900e+00  ...   1.6639e+00  1.6639e+00  5.3088e-01\n",
      "  9.7177e-01  9.7177e-01  1.9335e+00  ...   1.6639e+00  1.6639e+00  7.6070e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.6882e+00  1.6882e+00  1.9928e+00  ...   2.0553e+00  1.3358e+00  1.0011e+00\n",
      "  9.4341e-01  9.4341e-01  1.9928e+00  ...   2.0553e+00  1.3358e+00  1.0011e+00\n",
      "  9.4341e-01  9.4341e-01  6.8466e-01  ...   1.3358e+00  1.3358e+00  1.0011e+00\n",
      "[torch.cuda.FloatTensor of size 16x240x320 (GPU 0)]\n",
      "\n",
      "\n",
      "( 0 ,.,.) = \n",
      "  7.5964e-01  1.0950e+00  1.0950e+00  ...   1.5959e+00  4.7005e-01  4.3675e-01\n",
      "  7.5964e-01  1.0950e+00  1.0950e+00  ...   1.5959e+00  9.2514e-01  4.3675e-01\n",
      "  7.5964e-01  1.5366e+00  1.5366e+00  ...   1.5959e+00  9.2514e-01  4.3675e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.3831e+00  1.3831e+00  6.1270e-01  ...   2.6950e+00  1.9160e+00  1.9160e+00\n",
      "  7.5917e-01  7.5917e-01  6.4091e-01  ...   9.8323e-01  1.9160e+00  1.9160e+00\n",
      " -1.1915e-01  6.4091e-01  6.4091e-01  ...   9.8323e-01  1.9160e+00  1.9160e+00\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.0208e+00  1.0208e+00  1.2072e+00  ...   2.2230e+00  1.4877e+00  1.4877e+00\n",
      "  2.5027e+00  2.5027e+00  1.2072e+00  ...   2.2230e+00  1.4877e+00  1.4877e+00\n",
      "  2.5027e+00  2.5027e+00  1.2072e+00  ...   2.2230e+00  1.3808e+00  1.3808e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.6621e-01  6.6621e-01  4.0690e-01  ...   1.6483e+00  1.6483e+00  1.6483e+00\n",
      "  6.6621e-01  6.6621e-01  3.6104e-01  ...   1.9713e+00  1.9713e+00  1.6483e+00\n",
      "  2.9912e-01  2.9912e-01  2.9912e-01  ...   1.9713e+00  1.9713e+00  1.6483e+00\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -5.1021e-01  9.9461e-01  9.9461e-01  ...   1.2405e+00  1.4787e+00  1.4787e+00\n",
      "  1.9189e+00  1.9189e+00  1.6152e+00  ...   1.5492e+00  1.5492e+00  1.5492e+00\n",
      "  1.9189e+00  1.9189e+00  1.6152e+00  ...   1.5492e+00  1.5492e+00  1.5492e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  2.1397e+00  2.1397e+00  2.1397e+00  ...   9.7082e-01  1.6140e+00  1.6140e+00\n",
      "  1.7818e+00  1.7818e+00  1.6480e+00  ...   9.7082e-01  1.2620e+00  1.2620e+00\n",
      "  1.7818e+00  1.7818e+00  1.6480e+00  ...   9.7082e-01  1.2620e+00  1.2620e+00\n",
      "... \n",
      "\n",
      "(13 ,.,.) = \n",
      "  2.2417e+00  2.2417e+00  2.2417e+00  ...   1.7069e+00  1.8299e+00  1.8299e+00\n",
      "  2.2417e+00  2.2417e+00  2.2417e+00  ...   1.7069e+00  1.8299e+00  1.8299e+00\n",
      "  1.2107e+00  2.8876e+00  2.8876e+00  ...   1.4901e+00  1.8299e+00  1.8299e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  7.9232e-01  1.6065e+00  1.6065e+00  ...   1.2831e+00  1.2831e+00  1.2831e+00\n",
      "  7.9232e-01  1.6065e+00  1.7276e+00  ...   1.2831e+00  1.2831e+00  1.2831e+00\n",
      "  7.9232e-01  7.9232e-01  1.7276e+00  ...   3.3238e-01  3.3238e-01  2.5050e-01\n",
      "\n",
      "(14 ,.,.) = \n",
      "  2.3536e+00  2.3536e+00  2.2535e+00  ...   2.2923e+00  2.2923e+00  5.6515e-01\n",
      "  2.3536e+00  2.3536e+00  2.2535e+00  ...   2.2923e+00  2.2923e+00  1.3965e+00\n",
      "  2.3536e+00  2.3536e+00  1.9603e+00  ...   2.2923e+00  2.2923e+00  1.3965e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.7822e+00  1.7822e+00  1.7822e+00  ...   2.1175e+00  2.1175e+00  2.1175e+00\n",
      "  1.7822e+00  1.7822e+00  1.7822e+00  ...   2.1175e+00  2.1175e+00  2.1175e+00\n",
      "  1.7822e+00  1.7822e+00  1.7822e+00  ...   2.1175e+00  2.1175e+00  2.1175e+00\n",
      "\n",
      "(15 ,.,.) = \n",
      "  5.3173e-01  5.3173e-01  1.6900e+00  ...   3.2378e-01  3.2378e-01  2.4261e-01\n",
      "  5.3173e-01  5.5683e-01  1.6900e+00  ...   1.6639e+00  1.6639e+00  5.3088e-01\n",
      "  9.7177e-01  9.7177e-01  1.9335e+00  ...   1.6639e+00  1.6639e+00  7.6070e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.6882e+00  1.6882e+00  1.9928e+00  ...   2.0553e+00  1.3358e+00  1.0011e+00\n",
      "  9.4341e-01  9.4341e-01  1.9928e+00  ...   2.0553e+00  1.3358e+00  1.0011e+00\n",
      "  9.4341e-01  9.4341e-01  6.8466e-01  ...   1.3358e+00  1.3358e+00  1.0011e+00\n",
      "[torch.cuda.FloatTensor of size 16x240x320 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_m = pool_module(img_var)\n",
    "print out_m\n",
    "print out_m.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  7.5964e-01  1.0950e+00  1.0950e+00  ...   1.5959e+00  4.7005e-01  4.3675e-01\n",
      "  7.5964e-01  1.0950e+00  1.0950e+00  ...   1.5959e+00  9.2514e-01  4.3675e-01\n",
      "  7.5964e-01  1.5366e+00  1.5366e+00  ...   1.5959e+00  9.2514e-01  4.3675e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.3831e+00  1.3831e+00  6.1270e-01  ...   2.6950e+00  1.9160e+00  1.9160e+00\n",
      "  7.5917e-01  7.5917e-01  6.4091e-01  ...   9.8323e-01  1.9160e+00  1.9160e+00\n",
      " -1.1915e-01  6.4091e-01  6.4091e-01  ...   9.8323e-01  1.9160e+00  1.9160e+00\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.0208e+00  1.0208e+00  1.2072e+00  ...   2.2230e+00  1.4877e+00  1.4877e+00\n",
      "  2.5027e+00  2.5027e+00  1.2072e+00  ...   2.2230e+00  1.4877e+00  1.4877e+00\n",
      "  2.5027e+00  2.5027e+00  1.2072e+00  ...   2.2230e+00  1.3808e+00  1.3808e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.6621e-01  6.6621e-01  4.0690e-01  ...   1.6483e+00  1.6483e+00  1.6483e+00\n",
      "  6.6621e-01  6.6621e-01  3.6104e-01  ...   1.9713e+00  1.9713e+00  1.6483e+00\n",
      "  2.9912e-01  2.9912e-01  2.9912e-01  ...   1.9713e+00  1.9713e+00  1.6483e+00\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -5.1021e-01  9.9461e-01  9.9461e-01  ...   1.2405e+00  1.4787e+00  1.4787e+00\n",
      "  1.9189e+00  1.9189e+00  1.6152e+00  ...   1.5492e+00  1.5492e+00  1.5492e+00\n",
      "  1.9189e+00  1.9189e+00  1.6152e+00  ...   1.5492e+00  1.5492e+00  1.5492e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  2.1397e+00  2.1397e+00  2.1397e+00  ...   9.7082e-01  1.6140e+00  1.6140e+00\n",
      "  1.7818e+00  1.7818e+00  1.6480e+00  ...   9.7082e-01  1.2620e+00  1.2620e+00\n",
      "  1.7818e+00  1.7818e+00  1.6480e+00  ...   9.7082e-01  1.2620e+00  1.2620e+00\n",
      "... \n",
      "\n",
      "(13 ,.,.) = \n",
      "  2.2417e+00  2.2417e+00  2.2417e+00  ...   1.7069e+00  1.8299e+00  1.8299e+00\n",
      "  2.2417e+00  2.2417e+00  2.2417e+00  ...   1.7069e+00  1.8299e+00  1.8299e+00\n",
      "  1.2107e+00  2.8876e+00  2.8876e+00  ...   1.4901e+00  1.8299e+00  1.8299e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  7.9232e-01  1.6065e+00  1.6065e+00  ...   1.2831e+00  1.2831e+00  1.2831e+00\n",
      "  7.9232e-01  1.6065e+00  1.7276e+00  ...   1.2831e+00  1.2831e+00  1.2831e+00\n",
      "  7.9232e-01  7.9232e-01  1.7276e+00  ...   3.3238e-01  3.3238e-01  2.5050e-01\n",
      "\n",
      "(14 ,.,.) = \n",
      "  2.3536e+00  2.3536e+00  2.2535e+00  ...   2.2923e+00  2.2923e+00  5.6515e-01\n",
      "  2.3536e+00  2.3536e+00  2.2535e+00  ...   2.2923e+00  2.2923e+00  1.3965e+00\n",
      "  2.3536e+00  2.3536e+00  1.9603e+00  ...   2.2923e+00  2.2923e+00  1.3965e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.7822e+00  1.7822e+00  1.7822e+00  ...   2.1175e+00  2.1175e+00  2.1175e+00\n",
      "  1.7822e+00  1.7822e+00  1.7822e+00  ...   2.1175e+00  2.1175e+00  2.1175e+00\n",
      "  1.7822e+00  1.7822e+00  1.7822e+00  ...   2.1175e+00  2.1175e+00  2.1175e+00\n",
      "\n",
      "(15 ,.,.) = \n",
      "  5.3173e-01  5.3173e-01  1.6900e+00  ...   3.2378e-01  3.2378e-01  2.4261e-01\n",
      "  5.3173e-01  5.5683e-01  1.6900e+00  ...   1.6639e+00  1.6639e+00  5.3088e-01\n",
      "  9.7177e-01  9.7177e-01  1.9335e+00  ...   1.6639e+00  1.6639e+00  7.6070e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.6882e+00  1.6882e+00  1.9928e+00  ...   2.0553e+00  1.3358e+00  1.0011e+00\n",
      "  9.4341e-01  9.4341e-01  1.9928e+00  ...   2.0553e+00  1.3358e+00  1.0011e+00\n",
      "  9.4341e-01  9.4341e-01  6.8466e-01  ...   1.3358e+00  1.3358e+00  1.0011e+00\n",
      "[torch.FloatTensor of size 16x240x320]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_m_tensor = pool_module(img_tensor)\n",
    "out_m_tcuda = pool_module(img_tcuda)\n",
    "print out_m_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  7.5964e-01  1.0950e+00  1.0950e+00  ...   1.5959e+00  4.7005e-01  4.3675e-01\n",
      "  7.5964e-01  1.0950e+00  1.0950e+00  ...   1.5959e+00  9.2514e-01  4.3675e-01\n",
      "  7.5964e-01  1.5366e+00  1.5366e+00  ...   1.5959e+00  9.2514e-01  4.3675e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.3831e+00  1.3831e+00  6.1270e-01  ...   2.6950e+00  1.9160e+00  1.9160e+00\n",
      "  7.5917e-01  7.5917e-01  6.4091e-01  ...   9.8323e-01  1.9160e+00  1.9160e+00\n",
      " -1.1915e-01  6.4091e-01  6.4091e-01  ...   9.8323e-01  1.9160e+00  1.9160e+00\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.0208e+00  1.0208e+00  1.2072e+00  ...   2.2230e+00  1.4877e+00  1.4877e+00\n",
      "  2.5027e+00  2.5027e+00  1.2072e+00  ...   2.2230e+00  1.4877e+00  1.4877e+00\n",
      "  2.5027e+00  2.5027e+00  1.2072e+00  ...   2.2230e+00  1.3808e+00  1.3808e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.6621e-01  6.6621e-01  4.0690e-01  ...   1.6483e+00  1.6483e+00  1.6483e+00\n",
      "  6.6621e-01  6.6621e-01  3.6104e-01  ...   1.9713e+00  1.9713e+00  1.6483e+00\n",
      "  2.9912e-01  2.9912e-01  2.9912e-01  ...   1.9713e+00  1.9713e+00  1.6483e+00\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -5.1021e-01  9.9461e-01  9.9461e-01  ...   1.2405e+00  1.4787e+00  1.4787e+00\n",
      "  1.9189e+00  1.9189e+00  1.6152e+00  ...   1.5492e+00  1.5492e+00  1.5492e+00\n",
      "  1.9189e+00  1.9189e+00  1.6152e+00  ...   1.5492e+00  1.5492e+00  1.5492e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  2.1397e+00  2.1397e+00  2.1397e+00  ...   9.7082e-01  1.6140e+00  1.6140e+00\n",
      "  1.7818e+00  1.7818e+00  1.6480e+00  ...   9.7082e-01  1.2620e+00  1.2620e+00\n",
      "  1.7818e+00  1.7818e+00  1.6480e+00  ...   9.7082e-01  1.2620e+00  1.2620e+00\n",
      "... \n",
      "\n",
      "(13 ,.,.) = \n",
      "  2.2417e+00  2.2417e+00  2.2417e+00  ...   1.7069e+00  1.8299e+00  1.8299e+00\n",
      "  2.2417e+00  2.2417e+00  2.2417e+00  ...   1.7069e+00  1.8299e+00  1.8299e+00\n",
      "  1.2107e+00  2.8876e+00  2.8876e+00  ...   1.4901e+00  1.8299e+00  1.8299e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  7.9232e-01  1.6065e+00  1.6065e+00  ...   1.2831e+00  1.2831e+00  1.2831e+00\n",
      "  7.9232e-01  1.6065e+00  1.7276e+00  ...   1.2831e+00  1.2831e+00  1.2831e+00\n",
      "  7.9232e-01  7.9232e-01  1.7276e+00  ...   3.3238e-01  3.3238e-01  2.5050e-01\n",
      "\n",
      "(14 ,.,.) = \n",
      "  2.3536e+00  2.3536e+00  2.2535e+00  ...   2.2923e+00  2.2923e+00  5.6515e-01\n",
      "  2.3536e+00  2.3536e+00  2.2535e+00  ...   2.2923e+00  2.2923e+00  1.3965e+00\n",
      "  2.3536e+00  2.3536e+00  1.9603e+00  ...   2.2923e+00  2.2923e+00  1.3965e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.7822e+00  1.7822e+00  1.7822e+00  ...   2.1175e+00  2.1175e+00  2.1175e+00\n",
      "  1.7822e+00  1.7822e+00  1.7822e+00  ...   2.1175e+00  2.1175e+00  2.1175e+00\n",
      "  1.7822e+00  1.7822e+00  1.7822e+00  ...   2.1175e+00  2.1175e+00  2.1175e+00\n",
      "\n",
      "(15 ,.,.) = \n",
      "  5.3173e-01  5.3173e-01  1.6900e+00  ...   3.2378e-01  3.2378e-01  2.4261e-01\n",
      "  5.3173e-01  5.5683e-01  1.6900e+00  ...   1.6639e+00  1.6639e+00  5.3088e-01\n",
      "  9.7177e-01  9.7177e-01  1.9335e+00  ...   1.6639e+00  1.6639e+00  7.6070e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.6882e+00  1.6882e+00  1.9928e+00  ...   2.0553e+00  1.3358e+00  1.0011e+00\n",
      "  9.4341e-01  9.4341e-01  1.9928e+00  ...   2.0553e+00  1.3358e+00  1.0011e+00\n",
      "  9.4341e-01  9.4341e-01  6.8466e-01  ...   1.3358e+00  1.3358e+00  1.0011e+00\n",
      "[torch.cuda.FloatTensor of size 16x240x320 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  7.5964e-01  1.0950e+00  1.0950e+00  ...   1.5959e+00  4.7005e-01  4.3675e-01\n",
      "  7.5964e-01  1.0950e+00  1.0950e+00  ...   1.5959e+00  9.2514e-01  4.3675e-01\n",
      "  7.5964e-01  1.5366e+00  1.5366e+00  ...   1.5959e+00  9.2514e-01  4.3675e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.3831e+00  1.3831e+00  6.1270e-01  ...   2.6950e+00  1.9160e+00  1.9160e+00\n",
      "  7.5917e-01  7.5917e-01  6.4091e-01  ...   9.8323e-01  1.9160e+00  1.9160e+00\n",
      " -1.1915e-01  6.4091e-01  6.4091e-01  ...   9.8323e-01  1.9160e+00  1.9160e+00\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.0208e+00  1.0208e+00  1.2072e+00  ...   2.2230e+00  1.4877e+00  1.4877e+00\n",
      "  2.5027e+00  2.5027e+00  1.2072e+00  ...   2.2230e+00  1.4877e+00  1.4877e+00\n",
      "  2.5027e+00  2.5027e+00  1.2072e+00  ...   2.2230e+00  1.3808e+00  1.3808e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.6621e-01  6.6621e-01  4.0690e-01  ...   1.6483e+00  1.6483e+00  1.6483e+00\n",
      "  6.6621e-01  6.6621e-01  3.6104e-01  ...   1.9713e+00  1.9713e+00  1.6483e+00\n",
      "  2.9912e-01  2.9912e-01  2.9912e-01  ...   1.9713e+00  1.9713e+00  1.6483e+00\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -5.1021e-01  9.9461e-01  9.9461e-01  ...   1.2405e+00  1.4787e+00  1.4787e+00\n",
      "  1.9189e+00  1.9189e+00  1.6152e+00  ...   1.5492e+00  1.5492e+00  1.5492e+00\n",
      "  1.9189e+00  1.9189e+00  1.6152e+00  ...   1.5492e+00  1.5492e+00  1.5492e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  2.1397e+00  2.1397e+00  2.1397e+00  ...   9.7082e-01  1.6140e+00  1.6140e+00\n",
      "  1.7818e+00  1.7818e+00  1.6480e+00  ...   9.7082e-01  1.2620e+00  1.2620e+00\n",
      "  1.7818e+00  1.7818e+00  1.6480e+00  ...   9.7082e-01  1.2620e+00  1.2620e+00\n",
      "... \n",
      "\n",
      "(13 ,.,.) = \n",
      "  2.2417e+00  2.2417e+00  2.2417e+00  ...   1.7069e+00  1.8299e+00  1.8299e+00\n",
      "  2.2417e+00  2.2417e+00  2.2417e+00  ...   1.7069e+00  1.8299e+00  1.8299e+00\n",
      "  1.2107e+00  2.8876e+00  2.8876e+00  ...   1.4901e+00  1.8299e+00  1.8299e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  7.9232e-01  1.6065e+00  1.6065e+00  ...   1.2831e+00  1.2831e+00  1.2831e+00\n",
      "  7.9232e-01  1.6065e+00  1.7276e+00  ...   1.2831e+00  1.2831e+00  1.2831e+00\n",
      "  7.9232e-01  7.9232e-01  1.7276e+00  ...   3.3238e-01  3.3238e-01  2.5050e-01\n",
      "\n",
      "(14 ,.,.) = \n",
      "  2.3536e+00  2.3536e+00  2.2535e+00  ...   2.2923e+00  2.2923e+00  5.6515e-01\n",
      "  2.3536e+00  2.3536e+00  2.2535e+00  ...   2.2923e+00  2.2923e+00  1.3965e+00\n",
      "  2.3536e+00  2.3536e+00  1.9603e+00  ...   2.2923e+00  2.2923e+00  1.3965e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.7822e+00  1.7822e+00  1.7822e+00  ...   2.1175e+00  2.1175e+00  2.1175e+00\n",
      "  1.7822e+00  1.7822e+00  1.7822e+00  ...   2.1175e+00  2.1175e+00  2.1175e+00\n",
      "  1.7822e+00  1.7822e+00  1.7822e+00  ...   2.1175e+00  2.1175e+00  2.1175e+00\n",
      "\n",
      "(15 ,.,.) = \n",
      "  5.3173e-01  5.3173e-01  1.6900e+00  ...   3.2378e-01  3.2378e-01  2.4261e-01\n",
      "  5.3173e-01  5.5683e-01  1.6900e+00  ...   1.6639e+00  1.6639e+00  5.3088e-01\n",
      "  9.7177e-01  9.7177e-01  1.9335e+00  ...   1.6639e+00  1.6639e+00  7.6070e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.6882e+00  1.6882e+00  1.9928e+00  ...   2.0553e+00  1.3358e+00  1.0011e+00\n",
      "  9.4341e-01  9.4341e-01  1.9928e+00  ...   2.0553e+00  1.3358e+00  1.0011e+00\n",
      "  9.4341e-01  9.4341e-01  6.8466e-01  ...   1.3358e+00  1.3358e+00  1.0011e+00\n",
      "[torch.FloatTensor of size 16x240x320]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_F = F.max_pool2d(img_var, kernel_size=3, stride=1, padding=1)\n",
    "out_F_tensor = F.max_pool2d(img_tensor, kernel_size=3, stride=1, padding=1)\n",
    "out_F_tcuda = F.max_pool2d(img_tcuda, kernel_size=3, stride=1, padding=1)\n",
    "out_F_tensor_ = out_F_tensor.data\n",
    "out_F_tcuda_ = out_F_tcuda.data\n",
    "print out_F\n",
    "print out_F_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.907418\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(10000):\n",
    "    out_m = pool_module(img_var)\n",
    "end = time.clock()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.944827\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(10000):\n",
    "    out_F = F.max_pool2d(img_var, kernel_size=3, stride=1, padding=1)\n",
    "end = time.clock()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844869\n"
     ]
    }
   ],
   "source": [
    "img_tensor_cuda = img_tensor.cuda()\n",
    "start = time.clock()\n",
    "for i in range(10000):\n",
    "    out_F_tensor = F.max_pool2d(img_tensor_cuda, kernel_size=3, stride=1, padding=1)\n",
    "end = time.clock()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**结论： **\n",
    "- 采用 Variable 和 Tensor 作为输入都可以利用 GPU 加速。 `nn.Module` 和 `nn.Functional` 计算速度相近。\n",
    "- 先 .cuda 还是先 Variable 速度相近。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96083\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(1000):\n",
    "    img_var_cuda = Variable(img_tensor.cuda())\n",
    "end = time.clock()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869973\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(1000):\n",
    "    img_var_cuda = Variable(img_tensor).cuda()\n",
    "end = time.clock()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.882353\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(10000):\n",
    "    nms_var = img_var.eq(out_F).float().mul(img_var)\n",
    "end = time.clock()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "False\n",
      "True\n",
      "\n",
      "    0     0     2\n",
      "    0     0    12\n",
      "    0     0    15\n",
      "        ⋮         \n",
      "   15   239   308\n",
      "   15   239   312\n",
      "   15   239   314\n",
      "[torch.cuda.LongTensor of size 137578x3 (GPU 0)]\n",
      "\n",
      "\n",
      " 1.0950\n",
      " 0.2312\n",
      " 1.0859\n",
      "   ⋮   \n",
      " 3.6348\n",
      " 1.3108\n",
      " 0.9743\n",
      "[torch.cuda.FloatTensor of size 137578 (GPU 0)]\n",
      "\n",
      "\n",
      " 0.0000e+00\n",
      " 1.0000e+00\n",
      " 2.0000e+00\n",
      "     ⋮     \n",
      " 1.3758e+05\n",
      " 1.3758e+05\n",
      " 1.3758e+05\n",
      "[torch.cuda.LongTensor of size 137578 (GPU 0)]\n",
      "\n",
      "-0.0\n",
      "\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  1.0000e+00\n",
      " 0.0000e+00  0.0000e+00  2.0000e+00\n",
      "                 ⋮                  \n",
      " 1.5000e+01  2.3900e+02  1.3758e+05\n",
      " 1.5000e+01  2.3900e+02  1.3758e+05\n",
      " 1.5000e+01  2.3900e+02  1.3758e+05\n",
      "[torch.cuda.LongTensor of size 137578x3 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mask_var = torch.eq(img_var, out_F)\n",
    "print type(nms_var)\n",
    "print type(nms_var.data)\n",
    "print torch.is_tensor(nms_var)\n",
    "print torch.is_tensor(nms_var.data)\n",
    "p = torch.nonzero(mask_var.data)\n",
    "print p\n",
    "s = nms_var.masked_select(mask_var).data\n",
    "idxs = torch.arange(0, p.size(0)).long().cuda()\n",
    "print s\n",
    "print idxs\n",
    "print nms_var.data[0,0,11]\n",
    "print torch.cat((p[:,:-1],idxs.view(-1,1)),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64 float32\n",
      "0.0\n",
      "<type 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "p_n = p.cpu().numpy()\n",
    "s_n = s.view(-1,1).cpu().numpy()\n",
    "print p_n.dtype, s_n.dtype\n",
    "stack_n = np.concatenate((p_n, s_n),1)\n",
    "print stack_n[0,0]\n",
    "print type(stack_n[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    0     0     2\n",
      "    0     0    12\n",
      "    0     0    15\n",
      "        ⋮         \n",
      "   15   239   308\n",
      "   15   239   312\n",
      "   15   239   314\n",
      "[torch.cuda.LongTensor of size 137578x3 (GPU 0)]\n",
      "\n",
      "[torch.FloatTensor with no dimension]\n",
      "\n",
      "0\n",
      "[torch.FloatTensor with no dimension]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8531"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[:,-2:] = p[:,[3-1,3-2]]\n",
    "print p\n",
    "empty_tensor = torch.ones((0,2))\n",
    "print empty_tensor\n",
    "print len(empty_tensor.size())\n",
    "print torch.Tensor(0)\n",
    "p[:,0].eq(0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "( 0 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "( 1 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "( 2 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "... \n",
      "\n",
      "(13 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "(14 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "(15 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "[torch.cuda.FloatTensor of size 16x240x320 (GPU 0)]\n",
      "\n",
      "2.814209\n",
      "\n",
      "( 0 ,.,.) = \n",
      "   0   0   1  ...    0   0   0\n",
      "   1   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   1\n",
      "   1   0   1  ...    0   0   0\n",
      "\n",
      "( 1 ,.,.) = \n",
      "   1   0   0  ...    0   1   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   1   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   1   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "   0   0   0  ...    1   0   0\n",
      "\n",
      "( 2 ,.,.) = \n",
      "   0   0   0  ...    0   0   1\n",
      "   0   0   0  ...    0   0   0\n",
      "   1   0   0  ...    0   1   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   1   0   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   1\n",
      "... \n",
      "\n",
      "(13 ,.,.) = \n",
      "   0   1   0  ...    0   0   0\n",
      "   0   0   0  ...    0   0   1\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   1  ...    0   1   0\n",
      "   1   0   0  ...    0   0   0\n",
      "   0   0   0  ...    1   0   0\n",
      "\n",
      "(14 ,.,.) = \n",
      "   0   0   0  ...    0   0   1\n",
      "   1   0   0  ...    1   0   0\n",
      "   0   0   0  ...    0   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   0   1   0  ...    0   1   0\n",
      "   0   0   0  ...    0   0   0\n",
      "\n",
      "(15 ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "   1   0   0  ...    0   0   0\n",
      "   0   0   0  ...    1   0   0\n",
      "     ...       ⋱       ...    \n",
      "   0   0   0  ...    0   0   0\n",
      "   1   0   0  ...    0   0   1\n",
      "   0   0   0  ...    0   0   0\n",
      "[torch.cuda.ByteTensor of size 16x240x320 (GPU 0)]\n",
      "\n",
      "\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.0000 -0.2829  ...   0.0000  0.0000  0.0000\n",
      " -1.5102  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  1.4285\n",
      "  0.7060  0.0000 -0.0394  ...   0.0000  0.0000  0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0200  0.0000  0.0000  ...   0.0000 -0.1889  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.3164  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.7141  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.5841  0.0000  0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.1539\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " -1.2617  0.0000  0.0000  ...   0.0000  0.0499  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " -1.1819  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000 -0.6375\n",
      "... \n",
      "\n",
      "(13 ,.,.) = \n",
      "  0.0000 -2.1207  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0638\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000 -0.8722  ...   0.0000 -0.9932  0.0000\n",
      "  0.6139  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...  -0.9582  0.0000  0.0000\n",
      "\n",
      "(14 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  1.4647\n",
      "  1.1038  0.0000  0.0000  ...  -0.8323  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.9065  0.0000  ...   0.0000  0.3642  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "\n",
      "(15 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " -1.1302  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...  -0.3908  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.3781  0.0000  0.0000  ...   0.0000  0.0000 -1.8092\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "[torch.cuda.FloatTensor of size 16x240x320 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nms_tcuda = torch.zeros(img_tcuda.size()).cuda()\n",
    "print nms_tcuda\n",
    "mask_tcuda = img_tcuda.eq(out_F_tcuda_)\n",
    "start = time.clock()\n",
    "for i in range(10000):\n",
    "    nms_tcuda.masked_scatter_(mask_tcuda, img_tcuda)\n",
    "end = time.clock()\n",
    "print end - start\n",
    "print mask_tcuda\n",
    "print nms_tcuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0 ,.,.) = \n",
       "   1   1   0  ...    1   1   1\n",
       "   0   1   1  ...    1   1   1\n",
       "   1   1   1  ...    1   1   1\n",
       "     ...       ⋱       ...    \n",
       "   1   1   1  ...    1   1   1\n",
       "   1   1   1  ...    1   1   0\n",
       "   0   1   0  ...    1   1   1\n",
       "\n",
       "( 1 ,.,.) = \n",
       "   0   1   1  ...    1   0   1\n",
       "   1   1   1  ...    1   1   1\n",
       "   0   1   1  ...    1   1   1\n",
       "     ...       ⋱       ...    \n",
       "   0   1   1  ...    1   1   1\n",
       "   1   1   1  ...    1   1   1\n",
       "   1   1   1  ...    0   1   1\n",
       "\n",
       "( 2 ,.,.) = \n",
       "   1   1   1  ...    1   1   0\n",
       "   1   1   1  ...    1   1   1\n",
       "   0   1   1  ...    1   0   1\n",
       "     ...       ⋱       ...    \n",
       "   1   1   1  ...    1   1   1\n",
       "   0   1   1  ...    1   1   1\n",
       "   1   1   1  ...    1   1   0\n",
       "... \n",
       "\n",
       "(13 ,.,.) = \n",
       "   1   0   1  ...    1   1   1\n",
       "   1   1   1  ...    1   1   0\n",
       "   1   1   1  ...    1   1   1\n",
       "     ...       ⋱       ...    \n",
       "   1   1   0  ...    1   0   1\n",
       "   0   1   1  ...    1   1   1\n",
       "   1   1   1  ...    0   1   1\n",
       "\n",
       "(14 ,.,.) = \n",
       "   1   1   1  ...    1   1   0\n",
       "   0   1   1  ...    0   1   1\n",
       "   1   1   1  ...    1   1   1\n",
       "     ...       ⋱       ...    \n",
       "   1   1   1  ...    1   1   1\n",
       "   1   0   1  ...    1   0   1\n",
       "   1   1   1  ...    1   1   1\n",
       "\n",
       "(15 ,.,.) = \n",
       "   1   1   1  ...    1   1   1\n",
       "   0   1   1  ...    1   1   1\n",
       "   1   1   1  ...    0   1   1\n",
       "     ...       ⋱       ...    \n",
       "   1   1   1  ...    1   1   1\n",
       "   0   1   1  ...    1   1   0\n",
       "   1   1   1  ...    1   1   1\n",
       "[torch.cuda.ByteTensor of size 16x240x320 (GPU 0)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(nms_var.data, nms_tcuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91331\n",
      "\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.0000 -0.2829  ...   0.0000  0.0000  0.0000\n",
      " -1.5102  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  1.4285\n",
      "  0.7060  0.0000 -0.0394  ...   0.0000  0.0000  0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0200  0.0000  0.0000  ...   0.0000 -0.1889  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.3164  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.7141  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.5841  0.0000  0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.1539\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " -1.2617  0.0000  0.0000  ...   0.0000  0.0499  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " -1.1819  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000 -0.6375\n",
      "... \n",
      "\n",
      "(13 ,.,.) = \n",
      "  0.0000 -2.1207  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0638\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000 -0.8722  ...   0.0000 -0.9932  0.0000\n",
      "  0.6139  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...  -0.9582  0.0000  0.0000\n",
      "\n",
      "(14 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  1.4647\n",
      "  1.1038  0.0000  0.0000  ...  -0.8323  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.9065  0.0000  ...   0.0000  0.3642  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "\n",
      "(15 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " -1.1302  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...  -0.3908  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.3781  0.0000  0.0000  ...   0.0000  0.0000 -1.8092\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "[torch.cuda.FloatTensor of size 16x240x320 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(10000):\n",
    "    nms_tcuda_ = img_tcuda.eq(out_F_tcuda_).float().mul(img_tcuda)\n",
    "end = time.clock()\n",
    "print end - start\n",
    "print nms_tcuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113.235003\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(10000):\n",
    "    nms_tensor_ = img_tensor.eq(out_F_tensor_).float().mul(img_tensor)\n",
    "end = time.clock()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试 torch 的 in-place 运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.zeros(3,4)\n",
    "b = torch.ones(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1  1  1\n",
       " 1  1  1  1\n",
       " 1  1  1  1\n",
       "[torch.FloatTensor of size 3x4]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add_(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1  1  1\n",
       " 1  1  1  1\n",
       " 1  1  1  1\n",
       "[torch.FloatTensor of size 3x4]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       "[torch.FloatTensor of size 3x4]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mul_(torch.zeros(3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2  2  2  2\n",
      " 2  2  2  2\n",
      " 2  2  2  2\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = torch.ones(3,4).add_(b)\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d = torch.ones(3,4).mul_(torch.zeros(3,4))\n",
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 2  2  2  2\n",
      " 2  2  2  2\n",
      " 2  2  2  2\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  2  2  2\n",
       " 2  2  2  2\n",
       " 2  2  2  2\n",
       "[torch.FloatTensor of size 3x4]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print a\n",
    "print c\n",
    "a.max(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 1  1  1  1\n",
      " 1  1  1  1\n",
      " 1  1  1  1\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e = a\n",
    "print e\n",
    "e = e + 1\n",
    "print e\n",
    "print a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试 torch.cuda.Tensor 与 numpy 和 list 间的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1.0000\n",
      "  1.6429\n",
      "  2.2857\n",
      "  2.9286\n",
      "  3.5714\n",
      "  4.2143\n",
      "  4.8571\n",
      "  5.5000\n",
      "  6.1429\n",
      "  6.7857\n",
      "  7.4286\n",
      "  8.0714\n",
      "  8.7143\n",
      "  9.3571\n",
      " 10.0000\n",
      "[torch.FloatTensor of size 15]\n",
      "\n",
      "[  1.           1.64285714   2.28571429   2.92857143   3.57142857\n",
      "   4.21428571   4.85714286   5.5          6.14285714   6.78571429\n",
      "   7.42857143   8.07142857   8.71428571   9.35714286  10.        ]\n",
      "\n",
      " 2.0000\n",
      " 2.3571\n",
      " 2.7143\n",
      " 3.0714\n",
      " 3.4286\n",
      " 3.7857\n",
      " 4.1429\n",
      " 4.5000\n",
      " 4.8571\n",
      " 5.2143\n",
      " 5.5714\n",
      " 5.9286\n",
      " 6.2857\n",
      " 6.6429\n",
      " 7.0000\n",
      "[torch.FloatTensor of size 15]\n",
      "\n",
      "[ 2.          2.35714286  2.71428571  3.07142857  3.42857143  3.78571429\n",
      "  4.14285714  4.5         4.85714286  5.21428571  5.57142857  5.92857143\n",
      "  6.28571429  6.64285714  7.        ]\n"
     ]
    }
   ],
   "source": [
    "a_t = torch.linspace(1,10,steps=15)\n",
    "b_t = torch.linspace(2,7,steps=15)\n",
    "a_n = np.linspace(1,10,num=15)\n",
    "b_n = np.linspace(2,7,num=15)\n",
    "print a_t\n",
    "print a_n\n",
    "print b_t\n",
    "print b_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "z_n = zip(a_n, b_n)\n",
    "print type(z_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "z_t = zip(a_t, b_t)\n",
    "print type(z_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.120928\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(100000):\n",
    "    a_t = torch.linspace(1,10,steps=15)\n",
    "end = time.clock()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.694245\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(100000):\n",
    "    a_n = np.linspace(1,10,num=15)\n",
    "end = time.clock()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.694553\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(100000):\n",
    "    z_t = zip(a_t, b_t)\n",
    "end = time.clock()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.249546\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(100000):\n",
    "    torch.stack((a_t, b_t),dim=1)\n",
    "end = time.clock()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.167087\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(100000):\n",
    "    z_n = zip(a_n, b_n)\n",
    "end = time.clock()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.184043\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(100000):\n",
    "    np.hstack([a_n, b_n])\n",
    "end = time.clock()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.939868\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(100000):\n",
    "    a_t = torch.linspace(1,10,steps=15)\n",
    "    b_t = torch.linspace(2,7,steps=15)\n",
    "    z_t = zip(a_t, b_t)\n",
    "end = time.clock()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.591358\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(100000):\n",
    "    a_n = np.linspace(1,10,num=15)\n",
    "    b_n = np.linspace(2,7,num=15)\n",
    "    z_n = zip(a_n, b_n)\n",
    "end = time.clock()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 0.5], [2, 0, 0.3], [1, 3, 0.4], [3, 2, 0.7], [3, 5, 0.9], [4, 1, 0.6]]\n"
     ]
    }
   ],
   "source": [
    "cand = [[1,2,0.5],[2,0, 0.3],[1,3,0.4],[3,2,0.7],[3,5,0.9],[4,1,0.6]]\n",
    "print cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.251812\n",
      "[[3, 5, 0.9], [3, 2, 0.7], [4, 1, 0.6], [1, 2, 0.5], [1, 3, 0.4], [2, 0, 0.3]]\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(1000000):\n",
    "    cand = [[1,2,0.5],[2,0, 0.3],[1,3,0.4],[3,2,0.7],[3,5,0.9],[4,1,0.6]]\n",
    "    cand.sort(key=lambda x:x[2], reverse=True)\n",
    "end = time.clock()\n",
    "print end - start\n",
    "print cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.52901\n",
      "[[1, 2, 0.5], [2, 0, 0.3], [1, 3, 0.4], [3, 2, 0.7], [3, 5, 0.9], [4, 1, 0.6]]\n",
      "[[3, 5, 0.9], [3, 2, 0.7], [4, 1, 0.6], [1, 2, 0.5], [1, 3, 0.4], [2, 0, 0.3]]\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(1000000):\n",
    "    cand = [[1,2,0.5],[2,0, 0.3],[1,3,0.4],[3,2,0.7],[3,5,0.9],[4,1,0.6]]\n",
    "    cand_sort = sorted(cand, key=lambda x:x[2], reverse=True)\n",
    "end = time.clock()\n",
    "print end - start\n",
    "print cand\n",
    "print cand_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print a\n",
    "a_np = a.numpy()\n",
    "print a_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.590533\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(1000000):\n",
    "    a[1,3]\n",
    "end = time.clock()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.110179\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "for i in range(1000000):\n",
    "    a_np[1,3]\n",
    "end = time.clock()\n",
    "print end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa_n = np.arange(12).reshape((3,4))\n",
    "aa_t = torch.arange(0, 12).view(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "\n",
      "  0   1   2   3\n",
      "  4   5   6   7\n",
      "  8   9  10  11\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "[ 8  9 10 11]\n",
      "\n",
      "  8\n",
      "  9\n",
      " 10\n",
      " 11\n",
      "[torch.FloatTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print aa_n\n",
    "print aa_t\n",
    "print aa_n.max(axis=0)\n",
    "print aa_t.max(0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
